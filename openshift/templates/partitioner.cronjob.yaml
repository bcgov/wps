kind: "Template"
apiVersion: "template.openshift.io/v1"
metadata:
  name: partitioner-job-template
  annotations:
    description: "Cronjob to partition tables 1 month into the future."
    tags: "job,sfms"
labels:
  app.kubernetes.io/part-of: "${NAME}"
  app: ${NAME}-${SUFFIX}
parameters:
  - name: NAME
    description: Module name
    value: wps
  - name: SUFFIX
    description: Deployment suffix, e.g. pr-###
    required: true
  - name: GLOBAL_NAME
    description: Name of global Module
    value: wps-global
  - name: PROJ_TOOLS
    value: e1e498-tools
  - name: "TAG_NAME"
    displayName: "Environment TAG name"
    description: "The TAG name for the docker image"
    required: true
    value: "prod"
  - name: PG_DATABASE
    required: true
  - name: CRUNCHYDB_USER
    required: true
  - name: SCHEDULE
    required: true
  - name: APP_LABEL
    required: true
objects:
  - kind: CronJob
    apiVersion: batch/v1
    metadata:
      name: partitioner-${NAME}-${SUFFIX}
    spec:
      # Run every month on day 1 at 11:00
      schedule: ${SCHEDULE}
      # We use the "Replace" policy, because we never want the cronjobs to run concurrently,
      # and if for whatever reason a cronjob gets stuck, we want the next run to proceed.
      # If we were to use Forbid, and a cronjob gets stuck, then we'd stop gathering data until someone
      # noticed. We don't want that.
      concurrencyPolicy: "Replace"
      jobTemplate:
        metadata:
          labels:
            cronjob: partitioner-${NAME}-${SUFFIX}
            app: ${APP_LABEL}
        spec:
          template:
            spec:
              containers:
                - name: partitioner-${NAME}-${SUFFIX}
                  image: "image-registry.openshift-image-registry.svc:5000/${PROJ_TOOLS}/pgslice:${TAG_NAME}"
                  imagePullPolicy: "Always"
                  command:
                    ["bash", "partition_and_archive.sh", "${PG_DATABASE}"]
                  env:
                    - name: PG_USER
                      valueFrom:
                        secretKeyRef:
                          name: ${CRUNCHYDB_USER}
                          key: user
                    - name: PG_PASSWORD
                      valueFrom:
                        secretKeyRef:
                          name: ${CRUNCHYDB_USER}
                          key: password
                    - name: PG_HOSTNAME
                      valueFrom:
                        secretKeyRef:
                          name: ${CRUNCHYDB_USER}
                          key: pgbouncer-host
                    - name: PG_PORT
                      valueFrom:
                        secretKeyRef:
                          name: ${CRUNCHYDB_USER}
                          key: pgbouncer-port
                    - name: PG_DATABASE
                      value: ${PG_DATABASE}
                    - name: AWS_HOSTNAME
                      valueFrom:
                        secretKeyRef:
                          name: ${GLOBAL_NAME}
                          key: object-store-server
                    - name: AWS_ACCESS_KEY
                      valueFrom:
                        secretKeyRef:
                          name: ${GLOBAL_NAME}
                          key: object-store-user-id
                    - name: AWS_SECRET_KEY
                      valueFrom:
                        secretKeyRef:
                          name: ${GLOBAL_NAME}
                          key: object-store-secret
                    - name: AWS_BUCKET
                      valueFrom:
                        secretKeyRef:
                          name: ${GLOBAL_NAME}
                          key: object-store-bucket
                    - name: SUFFIX
                      value: ${SUFFIX}
                  resources:
                    limits:
                      memory: 256Mi
                    requests:
                      cpu: "256m"
                      memory: 128Mi
              restartPolicy: OnFailure
