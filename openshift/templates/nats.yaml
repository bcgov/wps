apiVersion: template.openshift.io/v1
kind: Template
metadata:
  name: nats
  annotations:
    "openshift.io/display-name": nats
parameters:
  - name: POD_NAMESPACE
    description: The pod namespace
    value: ${POD_NAMESPACE}
    required: true
  - name: SUFFIX
    description: Deployment suffix, e.g. pr-###
    required: true
  - name: APP_NAME
    description: Application name (wps - wildfire predictive services)
    value: wps
    required: true
  - name: IMAGE_REGISTRY
    description: Location where images are to be pulled
    value: image-registry.openshift-image-registry.svc:5000
    required: true
  - name: IMAGE_NAME
    required: true
  - name: IMAGE_TAG
    required: true
  - name: PROJ_TOOLS
    value: e1e498-tools
    required: true
  - name: GLOBAL_NAME
    description: Name of global Module
    value: wps-global
    required: true
  - name: CRUNCHYDB_USER
    description: Name of crunchydb user details key
    required: true
  - name: POSTGRES_DATABASE
    required: true
  - name: MEMORY_REQUEST
    required: true
    value: 3800Mi
  - name: MEMORY_LIMIT
    required: true
    value: 5000Mi
  - name: CPU_REQUEST
    required: true
    value: "1.5"

objects:
  - apiVersion: v1
    kind: ConfigMap
    metadata:
      name: ${APP_NAME}-${SUFFIX}-nats-config
      labels:
        app: ${APP_NAME}-${SUFFIX}
    data:
      nats.conf: |-
        pid_file: "/var/run/nats/nats.pid"
        http: 8222
        max_payload: 100Mb
        max_pending: 120Mb
        debug: false
        trace: false
        trace_verbose: false
        server_name: $POD_NAME
        cluster {
            port: 6222
            name: ${APP_NAME}-${SUFFIX}-nats-cluster
            routes [
               nats://${APP_NAME}-${SUFFIX}-nats-0.${APP_NAME}-${SUFFIX}-nats.${POD_NAMESPACE}.svc.cluster.local:6222
               nats://${APP_NAME}-${SUFFIX}-nats-1.${APP_NAME}-${SUFFIX}-nats.${POD_NAMESPACE}.svc.cluster.local:6222
               nats://${APP_NAME}-${SUFFIX}-nats-2.${APP_NAME}-${SUFFIX}-nats.${POD_NAMESPACE}.svc.cluster.local:6222
            ]
            cluster_advertise: $CLUSTER_ADVERTISE
            connect_retries: 50
        }
        accounts: {
            cli: { 
                jetstream: enable
                users: [
                    {user: cli, password: cli, permissions: {publish: ">", subscribe: ">"}}
                  ]
            },
            consumer: { 
                jetstream: enable
                users: [
                    {user: consumer, password: consumer, permissions: {publish: ">", subscribe: ">"}}
                  ]
            },
            $SYS: {
              users: [ 
                  {user:sys, password:sys}
              ]
            }
        }
        no_auth_user: consumer
        leafnodes {
          port: 7422
        }
        jetstream {
          store_dir: /data
          max_file: 5Gi
        }
  - apiVersion: v1
    kind: Service
    metadata:
      name: ${APP_NAME}-${SUFFIX}-nats
      labels:
        app: ${APP_NAME}-${SUFFIX}
    spec:
      selector:
        app: ${APP_NAME}-${SUFFIX}
      clusterIP: None
      ports:
        - name: client
          port: 4222
        - name: cluster
          port: 6222
        - name: monitor
          port: 8222
        - name: metrics
          port: 7777
        - name: leafnodes
          port: 7422
        - name: gateways
          port: 7522

  - apiVersion: apps/v1
    kind: StatefulSet
    metadata:
      name: ${APP_NAME}-${SUFFIX}-nats
      labels:
        app: ${APP_NAME}-${SUFFIX}
    spec:
      selector:
        matchLabels:
          app: ${APP_NAME}-${SUFFIX}
      replicas: 3
      serviceName: "${APP_NAME}-${SUFFIX}-nats"
      volumeClaimTemplates:
        - metadata:
            name: ${APP_NAME}-${SUFFIX}-nats
          spec:
            accessModes:
              - ReadWriteMany
            volumeMode: "Filesystem"
            persistentVolumeReclaimPolicy: Delete
            resources:
              requests:
                storage: 256M
      template:
        metadata:
          labels:
            app: ${APP_NAME}-${SUFFIX}
        spec:
          # Common volumes for the containers
          volumes:
            - name: config-volume
              configMap:
                name: ${APP_NAME}-${SUFFIX}-nats-config
            - name: pid
              emptyDir: {}
            - name: ${APP_NAME}-${SUFFIX}-nats
              persistentVolumeClaim:
                claimName: ${APP_NAME}-${SUFFIX}-nats

          # Required to be able to HUP signal and apply config reload
          # to the server without restarting the pod.
          shareProcessNamespace: true

          #################
          #               #
          #  NATS Server  #
          #               #
          #################
          terminationGracePeriodSeconds: 60
          containers:
            - name: ${APP_NAME}-${SUFFIX}-nats
              image: artifacts.developer.gov.bc.ca/docker-remote/nats:2.9.0-alpine
              resources:
                requests:
                  cpu: "100m"
                  memory: "256Mi"
                limits:
                  cpu: "250m"
                  memory: "1024Mi"
              ports:
                - containerPort: 4222
                  name: client
                - containerPort: 7422
                  name: leafnodes
                - containerPort: 6222
                  name: cluster
                - containerPort: 8222
                  name: monitor
                - containerPort: 7777
                  name: metrics
              command:
                - "nats-server"
                - "--config"
                - "/etc/nats-config/nats.conf"

              # Required to be able to define an environment variable
              # that refers to other environment variables.  This env var
              # is later used as part of the configuration file.
              env:
                - name: POD_NAME
                  valueFrom:
                    fieldRef:
                      fieldPath: metadata.name
                - name: POD_NAMESPACE
                  valueFrom:
                    fieldRef:
                      fieldPath: metadata.namespace
                - name: CLUSTER_ADVERTISE
                  value: $(POD_NAME).nats.$(POD_NAMESPACE).svc
                - name: TZ
                  value: America/Vancouver
              imagePullPolicy: Always
              volumeMounts:
                - mountPath: /etc/nats-config
                  name: config-volume
                - mountPath: /var/run/nats
                  name: pid
                - mountPath: /data
                  name: ${APP_NAME}-${SUFFIX}-nats

        # Liveness/Readiness probes against the monitoring .
        livenessProbe:
          httpGet:
            path: /
            port: 8222
          initialDelaySeconds: 10
          timeoutSeconds: 5
        readinessProbe:
          httpGet:
            path: /
            port: 8222
          initialDelaySeconds: 10
          timeoutSeconds: 5

        # Gracefully stop NATS Server on pod deletion or image upgrade.
        #
        lifecycle:
          preStop:
            exec:
              # Using the alpine based NATS image, we add an extra sleep that is
              # the same amount as the terminationGracePeriodSeconds to allow
              # the NATS Server to gracefully terminate the client connections.
              #
              command:
                [
                  "/bin/sh",
                  "-c",
                  "/nats-server -sl=ldm=/var/run/nats/nats.pid && /bin/sleep 60",
                ]
  - apiVersion: apps/v1
    kind: Deployment
    metadata:
      name: ${APP_NAME}-${SUFFIX}-nats-consumer
      labels:
        app: ${APP_NAME}-${SUFFIX}
      annotations:
        image.openshift.io/triggers: |-
          [
            {
              "from": {
                "kind": "ImageStreamTag",
                "name": "${IMAGE_NAME}:${IMAGE_TAG}",
                "namespace": "${PROJ_TOOLS}"
              },
              "fieldPath": "spec.template.spec.containers[0].image"
            }
          ]
    spec:
      replicas: 3
      selector:
        matchLabels:
          app: ${APP_NAME}-${SUFFIX}
      template:
        metadata:
          labels:
            app: ${APP_NAME}-${SUFFIX}
        spec:
          containers:
            - name: ${APP_NAME}-${SUFFIX}-nats-consumer
              image: ${IMAGE_REGISTRY}/${PROJ_TOOLS}/${IMAGE_NAME}:${IMAGE_TAG}
              imagePullPolicy: "Always"
              resources:
                requests:
                  cpu: ${CPU_REQUEST}
                  memory: ${MEMORY_REQUEST}
                limits:
                  memory: ${MEMORY_LIMIT}
              command:
                [
                  "uv",
                  "run",
                  "--no-sync",
                  "python",
                  "-m",
                  "app.auto_spatial_advisory.nats_consumer",
                ]
              env:
                - name: NATS_STREAM_PREFIX
                  value: ${APP_NAME}-${SUFFIX}
                - name: NATS_SERVER
                  valueFrom:
                    configMapKeyRef:
                      name: ${APP_NAME}-${SUFFIX}-nats-server
                      key: nats.server
                - name: POSTGRES_READ_USER
                  valueFrom:
                    secretKeyRef:
                      name: ${CRUNCHYDB_USER}
                      key: user
                - name: POSTGRES_WRITE_USER
                  valueFrom:
                    secretKeyRef:
                      name: ${CRUNCHYDB_USER}
                      key: user
                - name: POSTGRES_PASSWORD
                  valueFrom:
                    secretKeyRef:
                      name: ${CRUNCHYDB_USER}
                      key: password
                - name: POSTGRES_WRITE_HOST
                  valueFrom:
                    secretKeyRef:
                      name: ${CRUNCHYDB_USER}
                      key: pgbouncer-host
                - name: POSTGRES_READ_HOST
                  valueFrom:
                    secretKeyRef:
                      name: ${CRUNCHYDB_USER}
                      key: pgbouncer-host
                - name: POSTGRES_PORT
                  valueFrom:
                    secretKeyRef:
                      name: ${CRUNCHYDB_USER}
                      key: pgbouncer-port
                - name: POSTGRES_DATABASE
                  value: ${POSTGRES_DATABASE}
                - name: OBJECT_STORE_SERVER
                  valueFrom:
                    secretKeyRef:
                      name: ${GLOBAL_NAME}
                      key: object-store-server
                - name: OBJECT_STORE_USER_ID
                  valueFrom:
                    secretKeyRef:
                      name: ${GLOBAL_NAME}
                      key: object-store-user-id
                - name: OBJECT_STORE_SECRET
                  valueFrom:
                    secretKeyRef:
                      name: ${GLOBAL_NAME}
                      key: object-store-secret
                - name: OBJECT_STORE_BUCKET
                  valueFrom:
                    secretKeyRef:
                      name: ${GLOBAL_NAME}
                      key: object-store-bucket
                - name: REDIS_USE
                  valueFrom:
                    configMapKeyRef:
                      name: ${GLOBAL_NAME}
                      key: env.redis-use
                - name: REDIS_HOST
                  valueFrom:
                    configMapKeyRef:
                      name: ${GLOBAL_NAME}
                      key: env.redis-host
                - name: REDIS_PORT
                  valueFrom:
                    configMapKeyRef:
                      name: ${GLOBAL_NAME}
                      key: env.redis-port
                - name: REDIS_PASSWORD
                  valueFrom:
                    secretKeyRef:
                      name: wps-redis
                      key: database-password
                - name: REDIS_STATION_CACHE_EXPIRY
                  valueFrom:
                    configMapKeyRef:
                      name: ${GLOBAL_NAME}
                      key: env.redis-station-cache-expiry
                - name: REDIS_HOURLIES_BY_STATION_CODE_CACHE_EXPIRY
                  valueFrom:
                    configMapKeyRef:
                      name: ${GLOBAL_NAME}
                      key: env.redis-hourlies-by-station-code-cache-expiry
                - name: REDIS_AUTH_CACHE_EXPIRY
                  valueFrom:
                    configMapKeyRef:
                      name: ${GLOBAL_NAME}
                      key: env.redis-auth-cache-expiry
                - name: WFWX_BASE_URL
                  valueFrom:
                    configMapKeyRef:
                      name: ${GLOBAL_NAME}
                      key: env.wfwx-base-url
                - name: WFWX_AUTH_URL
                  valueFrom:
                    configMapKeyRef:
                      name: ${GLOBAL_NAME}
                      key: env.wfwx-auth-url
                - name: WFWX_USER
                  valueFrom:
                    configMapKeyRef:
                      name: ${GLOBAL_NAME}
                      key: env.wfwx-user
                - name: WFWX_SECRET
                  valueFrom:
                    secretKeyRef:
                      name: ${GLOBAL_NAME}
                      key: wfwx-secret
                - name: DEM_NAME
                  valueFrom:
                    configMapKeyRef:
                      name: ${GLOBAL_NAME}
                      key: env.dem_name
                - name: CLASSIFIED_TPI_DEM_NAME
                  valueFrom:
                    configMapKeyRef:
                      name: ${GLOBAL_NAME}
                      key: env.classified_tpi_dem_name
                - name: FUEL_RASTER_NAME
                  valueFrom:
                    configMapKeyRef:
                      name: ${GLOBAL_NAME}
                      key: env.fuel_raster_name
              ports:
                - containerPort: 4222
                  name: client
                - containerPort: 7422
                  name: leafnodes
                - containerPort: 6222
                  name: cluster
                - containerPort: 8222
                  name: monitor
                - containerPort: 7777
                  name: metrics
